{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with RadIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first notebook in series of tutorials covering deep learning research of lung cancer using RadIO. Here you will (1) learn about general approach of RadIO when working with dataset of scans and (2) perform basic preprocessing operations (load of data into memory and resize of scans). As you will see in a minute, the (1) will save you the trouble of looping through the dataset that cannot fit into memory. In turn, learning (2) will give you a good idea of how one can build complex preprocessing pipelines using RadIO.\n",
    "\n",
    "In this tutorial you will work with [LUNA16 competition dataset](https://luna16.grand-challenge.org/), consisting of 888 cancer-annotated examples of scans of Computational Tomography (CT-scans). Annotations is simply a csv-table that contains location and diameter of cancerous nodules. In order to follow the tutorial, we advice you to download at least part of this dataset on [this link](https://luna16.grand-challenge.org/download/) (you will need a registration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with dataset of scans with ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first thing that one should understand about CT-scans is that they are **voluminous**. It is not possible to fit more than a few scans into memory. The only way to work with such large datasets is through an **indexing structure**. In RadIO, you can create this structure in three lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LUNA_MASK = '/data/MRT/luna/s*/*.mhd'      # set mask for scans from Luna-dataset here\n",
    "from radio.batchflow import FilesIndex\n",
    "luna_index = FilesIndex(path=LUNA_MASK, no_ext=True) # preparing indexing structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RadIO works with scans using *batch-classes* **`CTImagesBatch`** and **`CTImagesMaskedBatch`**, which describe the logic of processing batches of CT-scans (`load` of data from disk, `resize` of scans to different shape). When we combine data processing logic and the index, we obtain the `dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radio.batchflow import Dataset\n",
    "from radio import CTImagesMaskedBatch\n",
    "luna_dataset = Dataset(index=luna_index, batch_class=CTImagesMaskedBatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..and that's it, all necessary prerequisities are set up. It is time to get your hands on real data-processing operations of RadIO: `load` and `resize`.\n",
    "##### Note\n",
    "RadIO works with datasets using the **Batchflow-framework.** Check [the link](https://github.com/analysiscenter/batchflow) to find out more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing with RadIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 `Load` of data from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RadIO-team thinks of **preprocessing** as of chained sequence of operations, called `actions`. A sequence of actions is called `Pipeline`. Whichever preprocessing you want to do, you should start with setting up a pipeline in **lazy-mode**. That is, you only provide a **plan** of what will happen with data and no real computation is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost, you need to load scans data from disk. Let us set up a short pipeline for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radio.batchflow import Pipeline\n",
    "preprocessing = Pipeline()                     # initialize empty Pipeline-object\n",
    "preprocessing = preprocessing.load(fmt='raw')  # the thing is lazy. No calculation is performed here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did was to assemble a `Pipeline` with one action `load` with arguments `fmt=\"raw\"`. Argument `fmt` specifies the format of data and `raw` stands for [MetaImage-format](https://itk.org/Wiki/ITK/MetaIO/Documentation) which is used for Luna-dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real calculation starts only when we pass a dataset through a pipeline. E.g., you can generate a batch of 3 scans with loaded data with this line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = (luna_dataset >> preprocessing).next_batch(batch_size=3, shuffle=False)  # execution starts when you call next_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the line above, you generated an empty batch, containing 3 scans-indices, and passed it through the sequence of actions. In this specific case, there was only one action in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot an axial slice of a scan from batch and make sure that the data was loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_slices\n",
    "show_slices(batch, scan_indices=0, ns_slice=69, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 `Resize`: changing shape of scans-data using interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the loaded scan has shape **[179, 512, 512]** (**179** slices of shape **[512, 512]**). Clearly, the scan of such shape can eat **a lot** of GPU-memory. This can be a problem, if our goal is to build complex deep learning algorithms. Naturally, you may want to **resize** scans to a lesser shape without loosing much information. For this purpose you only need to add action `resize` to your preprocessing pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing = preprocessing.resize(shape=(92, 256, 256)) # remember, nothing is executed here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can build preprocessing pipeline from scratch, chaining all actions you need. RadIO-team advises to follow this approach. In that way, you can easily see all operations included in the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing = (Pipeline()                     # Initialize empty pipeline \n",
    "                 .load(fmt='raw')               # load data from disk\n",
    "                 .resize(shape=(92, 256, 256))) # resize to shape (92, 256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now pass a batch of 3 scans through the preprocessing workflow (which now contains two actions: `load` and `resize`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = (luna_dataset >> preprocessing).next_batch(batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..and see the result for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices(batch, scan_indices=0, ns_slice=35, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the scan now has different shape. In the same time, the content is roughly the same. Of course, `load` and `resize` are not the only actions implemented in RadIO. RadIO also includes actions\n",
    "* `unify_spacing` (reshape scans so that spacings between different scans be the same: say, **[1.0, 1.0, 1.0]** mms).\n",
    "* `dump` (preprocessed scans-data on disk for future use).\n",
    "* `rotate` (the scans about z-axis for dataset-augmentation).\n",
    "* `sample_nodules` (for cropping out small, cancerous and noncancerous, parts of scans for more efficient use of scans-dataset).\n",
    "\n",
    "..and many more\n",
    "\n",
    "Go [here](https://analysiscenter.github.io/radio/intro/preprocessing.html) to see the full list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading this tutorial you should be able to\n",
    "* Build a `Dataset` of computational tomogrpahy-scans from Luna-dataset, where `Dataset` is a structure, that indexes a large dataset on disk.\n",
    "* Build simple preprocessing pipelines, that contain `load` of data from disk and `resize` of scans to different shape.\n",
    "* Pass batches through pipelines using `next_batch`, thus changing the content of batches.\n",
    "\n",
    "In the [next tutorial](https://github.com/analysiscenter/radio/blob/master/tutorials/RadIO.II.ipynb) you can dive deeper into preprocessing-capabilities of RadIO and build a full-fledged preprocessing workflow that ends with creating *cancerous masks*, which can be used as a **target** for a segmenting net (e.g., [VNet](https://arxiv.org/abs/1606.04797))."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
