{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building cancer-detection system with RadIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to use data from the [LUNA Challenge](https://luna16.grand-challenge.org/Home/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FOLDER = '/home/alexander/Work/Notebooks/Old/PyData' # your local path to folder where the downloaded data folder lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert 'data' in os.listdir(PATH_TO_FOLDER)\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CT-scans and Lung-cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "from utils import pil_plot_slices, load_example, show_slices, get_pixel_coords, show_images\n",
    "\n",
    "import radio\n",
    "from radio.batchflow import FilesIndex, Dataset, Pipeline\n",
    "from radio import CTImagesMaskedBatch as CTIMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CT-scans are 3d-arrays of data. Cancer in lungs is represented in *pulmonary nodules*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scan and a corresponding mask\n",
    "PATH_TO_SAMPLE = os.path.join(PATH_TO_FOLDER, 'data/scans_sample/')\n",
    "\n",
    "bch = load_example(PATH_TO_SAMPLE, radio)\n",
    "interact(lambda height: pil_plot_slices(height, bch.get(0, 'images'), bch.get(0, 'masks')),\n",
    "         height=(0, 0.99, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building detection system-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dataset`, `Pipeline` and `Batch`-class on `MNIST`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CT-scans are voluminous. It is not possible to store all scans from the dataset in memory at once. In order to work with such datasets we use\n",
    "* `Dataset` and `Batch`-classes which capture **indexing structure and the logic** of data-processing\n",
    "* `Pipeline`s which represent **sequences** of data-processing actions\n",
    "\n",
    "Let us set up these structures for `MNIST`-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MNIST = os.path.join(PATH_TO_FOLDER, 'data/mnist_subset/*blk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing *index*, a structure that indexes files on disk (or somewhere else):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistindex = FilesIndex(path=PATH_TO_MNIST, no_ext=True)\n",
    "# that is, we need all files with .blk extension in a certan directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistindex.indices[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic of data-processing is implemented in `Batch`-classes. We use `ImageBatch` for `MNIST`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radio.batchflow import ImagesBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When combining `Batch`-class and `Index` you get `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistset = Dataset(index=mnistindex, batch_class=ImagesBatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before starting any computations you need a plan - `pipeline`. `pipeline` is a sequence of `actions` from the `Batch`-class you use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing is computed here!! it's only a plan\n",
    "pipeline = (Pipeline()\n",
    "            .load(fmt='blosc', components=['images', 'labels'])  # load data from disk\n",
    "            .sp_resize((23, 23)))                                # perform resize of mnist pics from (28, 28) to (23, 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real computation starts when you pass a part of your `Dataset`, a `Batch`, through the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bch = (mnistset >> pipeline).next_batch(batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(bch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's your turn now!\n",
    "Let's get back to CT-scans and cancer now! In this section you need to assemble a small pipeline, that `load`s scans from disk and `resize`s them.\n",
    "\n",
    "(We will help you, of course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set up the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_scans_sample = os.path.join(PATH_TO_FOLDER, 'data/sample_raw/*.mhd')\n",
    "luna_index = FilesIndex(path=path_to_scans_sample, no_ext=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luna_index.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic of data-processing in `RadIO` is implemented in `CTImagesMaskedBatch`-class, or `CTIMB`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radio import CTImagesMaskedBatch as CTIMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `CTIMB` and created index to set up a `Dataset` of scans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunaset = Dataset(index=luna_index, batch_class=CTIMB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make sure that everything is OK, run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunaset.indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to load scans from format (`fmt`-arg) `raw` and `resize` them to `shape=(256, 384, 384)`. Note that you need `components=['images', 'spacing', 'origin']`\n",
    "\n",
    "First, set up the plan of actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = (Pipeline()\n",
    "                 .load(fmt='raw', components=['images', 'spacing', 'origin'])\n",
    "                 .resize(shape=(256, 384, 384)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the computations by passing a part of `lunaset` through your `pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to get one item! So, batch_size=1 \n",
    "batch = (lunaset >> preprocessing).next_batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices(batch, scan_indices=[0], ns_slice=[128], grid=True, clims=(-1200, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going on with `preprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luna-dataset provides cancer-annotations for targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNO_PATH = os.path.join(PATH_TO_FOLDER, 'data/annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nodules_df = pd.read_csv(ANNO_PATH)\n",
    "nodules_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make use of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing += (Pipeline()\n",
    "                  .fetch_nodules_info(nodules_df)\n",
    "                  .create_mask()\n",
    "                  .normalize_hu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we normalize data-range to [0, 255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you need to `dump` preprocessed scans and get back to them later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumping = (Pipeline()\n",
    "           .dump(fmt='blosc', dst=os.path.join(PATH_TO_FOLDER, 'data/dump_dir/'),\n",
    "                 components=['images', 'masks', 'spacing', 'origin'], i8_encoding_mode='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = (lunaset >> (preprocessing + dumping)).next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (lunaset >> preprocessing).next_batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices(batch, scan_indices=[0, 0], ns_slice=[156, 156], grid=True, clims=[(0, 255), (0, 1)],\n",
    "            components=['images', 'masks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at two scans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_scans_dataset = Dataset(index=FilesIndex(path=os.path.join(PATH_TO_FOLDER, 'data/raw_blosc/*'), sort=True,\n",
    "                            dirs=True), batch_class=CTIMB)\n",
    "\n",
    "preprocessing_raw = Pipeline().load(fmt='blosc', components=['images', 'spacing', 'origin'])\n",
    "batch = (two_scans_dataset >> preprocessing_raw).next_batch(2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_slices(batch, scan_indices=[0, 1], ns_slice=list(batch.images_shape[:, 0] // 2), grid=True, clims=(0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the lungs are larger on the left scan. This can be explained by a big difference in scale (represented by a grid). This can be a source of uncontrollable variation in the training dataset. In order to make scans more isotropic, we add action `unify_spacing` to our preprocessing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (100, 256, 256)\n",
    "SPACING = (1.7, 1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_raw += (Pipeline()\n",
    "                      .unify_spacing(spacing=SPACING, shape=SHAPE, padding='constant'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass a batch through the workflow and see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (two_scans_dataset >> preprocessing_raw).next_batch(2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices(batch, scan_indices=[0, 1], ns_slice=list(batch.images_shape[:, 0] // 2), grid=True, clims=(0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUNA_BLOSC = os.path.join(PATH_TO_FOLDER, 'data/scans_sample/*')\n",
    "luna_blosc = Dataset(FilesIndex(path=LUNA_BLOSC, dirs=True), batch_class=CTIMB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add some augmentation actions to the workflow. To begin with, let's *controllably* introduce variation into the scale by randomly zooming in/zooming out on scans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing_options = [(1.7, 0.8, 0.8), (1.7, 1.0, 1.0), (1.7, 1.2, 1.2), (1.7, 1.4, 1.4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we define spacing randomizer, a function that randomly fetches spacing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing_randomizer = lambda *args: spacing_options[np.random.choice(range(len(spacing_options)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = (Pipeline()\n",
    "                 .load(fmt='blosc', components=['images', 'spacing', 'origin', 'masks'])\n",
    "                 .fetch_nodules_from_mask()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radio.batchflow import F\n",
    "augmentation = (Pipeline()\n",
    "                 .rotate(random=True, angle=10, components=['images', 'masks'])\n",
    "                 .unify_spacing(spacing=F(spacing_randomizer), shape=(128, 256, 256), padding='constant'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add some rotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch = (luna_blosc >> (preprocessing + augmentation)).next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(lambda height: pil_plot_slices(height, batch.get(0, 'images'), batch.get(0, 'masks')),\n",
    "         height=(0, 0.99, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIPs: a way to reduce 3d-problem to a 2d-one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach of participants in `Kaggle-DsBowl` and `Luna-challenge`: train network on small crops as 1) modern **GPUs** are just not enough to store full scans and 2) it's a way of augmenting the dataset. This approach leads to inference that takes **a lot** of time. Our approach: add *Maximum Intensity Projection (MIP)* in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xips = batch.xip('images', mode='max', depth=7, stride=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lxip = int(len(xips) / len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(lambda height: pil_plot_slices(height, batch.get(0, 'images'), xips[0:lxip, :, :, 0],\n",
    "                                        batch.get(0, 'masks')),\n",
    "         height=(0, 0.99, 0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module `dataset` contains a zoo of neural network models written on `tensorflow` and (coming soon) `pytorch`. Firstly, choose a model from the zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more imports\n",
    "import tensorflow as tf\n",
    "from radio.batchflow import B, V, F\n",
    "from radio.batchflow.models.tf import TFModel, UNet\n",
    "from radio.batchflow.models.tf.losses import dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is configuring a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    inputs=dict(\n",
    "        images=dict(shape=(256, 256, 1)),\n",
    "        masks=dict(shape=(256, 256, 1), name='targets')\n",
    "    ),\n",
    "    initial_block=dict(inputs='images'),\n",
    "    output=dict(ops='sigmoid'),\n",
    "    loss=dice,\n",
    "    optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model in pipeline, assemble training pipeline\n",
    "XIP_PARAMS = dict(mode='max', depth=16, stride=12, channels=1)\n",
    "model_training = (Pipeline()\n",
    "                  .init_model('static', UNet, 'unet', model_config)\n",
    "                  .train_model('unet', feed_dict=dict(images=F(CTIMB.xip, component='images', **XIP_PARAMS),\n",
    "                                                      masks=F(CTIMB.xip, component='masks', **XIP_PARAMS))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combining all parts into one workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = (preprocessing + augmentation + model_training) << luna_blosc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERS = 1\n",
    "for i in range(N_ITERS):\n",
    "    #workflow.next_batch(1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Inference using pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUNA_BLOSC = os.path.join(PATH_TO_FOLDER, 'data/scans_sample/*')\n",
    "luna_blosc = Dataset(FilesIndex(path=LUNA_BLOSC, dirs=True), batch_class=CTIMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from radio.batchflow import B, V, F\n",
    "from radio.batchflow.models.tf import TFModel\n",
    "\n",
    "model_path = os.path.join(PATH_TO_FOLDER, 'data/unet/e_6_3c_unet/models/logloss/')\n",
    "config = dict(load=dict(path=model_path),\n",
    "              session=dict(config=tf.ConfigProto(allow_soft_placement=True)))\n",
    "\n",
    "XIP_PARAMS = dict(mode='max', depth=6, stride=2, channels=3)\n",
    "\n",
    "ppl_predict_scan = (Pipeline()\n",
    "                    .init_model('static', TFModel, 'xipnet', config)\n",
    "                    .load(fmt='blosc', components=['images', 'spacing', 'origin', 'masks'])\n",
    "                    .fetch_nodules_from_mask()\n",
    "                    .init_variables(['predictions', 'nodules_true', 'nodules_predicted'])\n",
    "                    .fetch_nodules_from_mask()\n",
    "                    .update_variable('nodules_true', B('nodules'))\n",
    "                    .predict_model('xipnet', save_to=V('predictions'),\n",
    "                                   feed_dict=dict(images=F(CTIMB.xip, component='images', **XIP_PARAMS)))\n",
    "                    .call(CTIMB.unxip, xip=V('predictions'), squeeze=True, **XIP_PARAMS,\n",
    "                          component='predictions')\n",
    "                    .fetch_nodules_from_mask()\n",
    "                    .update_variable('nodules_predicted', B('nodules')) << luna_blosc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btch = ppl_predict_scan.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(lambda height: pil_plot_slices(height, btch.get(0, 'images'), btch.masks, \n",
    "                                        btch.predictions), height=(0, 0.99, 0.01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
